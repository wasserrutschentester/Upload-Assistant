name: Python Code Analysis Comment

on:
  workflow_run:
    workflows: ["Python Code Analysis"]
    types:
      - completed

permissions:
  contents: read
  actions: read
  issues: write
  pull-requests: write

jobs:
  pr-comment:
    if: github.event.workflow_run.event == 'pull_request' && github.event.workflow_run.conclusion != 'skipped'
    runs-on: ubuntu-latest

    steps:
    - name: Download Bandit Results
      uses: actions/download-artifact@v4
      with:
        run-id: ${{ github.event.workflow_run.id }}
        repository: ${{ github.repository }}
        github-token: ${{ secrets.GITHUB_TOKEN }}
        pattern: bandit-results-*
        merge-multiple: true
        path: artifacts

    - name: Download Safety Results
      uses: actions/download-artifact@v4
      with:
        run-id: ${{ github.event.workflow_run.id }}
        repository: ${{ github.repository }}
        github-token: ${{ secrets.GITHUB_TOKEN }}
        pattern: safety-results-*
        merge-multiple: true
        path: artifacts

    - name: Download Pyright Results
      uses: actions/download-artifact@v4
      with:
        run-id: ${{ github.event.workflow_run.id }}
        repository: ${{ github.repository }}
        github-token: ${{ secrets.GITHUB_TOKEN }}
        pattern: pyright-results-*
        merge-multiple: true
        path: artifacts

    - name: Download Ruff Results
      uses: actions/download-artifact@v4
      with:
        run-id: ${{ github.event.workflow_run.id }}
        repository: ${{ github.repository }}
        github-token: ${{ secrets.GITHUB_TOKEN }}
        pattern: ruff-results-*
        merge-multiple: true
        path: artifacts

    - name: Download Deprecation Warnings
      uses: actions/download-artifact@v4
      with:
        run-id: ${{ github.event.workflow_run.id }}
        repository: ${{ github.repository }}
        github-token: ${{ secrets.GITHUB_TOKEN }}
        pattern: deprecation-warnings-*
        merge-multiple: true
        path: artifacts

    - name: Post Results to PR
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');

          const workflowRun = context.payload.workflow_run;
          const prs = workflowRun.pull_requests || [];

          async function resolvePrNumber() {
            if (prs.length > 0) {
              return { number: prs[0].number, source: 'workflow_run.pull_requests[0]' };
            }

            const headRepo = workflowRun.head_repository && workflowRun.head_repository.owner
              ? workflowRun.head_repository.owner.login
              : null;
            const headBranch = workflowRun.head_branch || null;
            const headSha = workflowRun.head_sha || null;

            if (headRepo && headBranch) {
              const headRef = `${headRepo}:${headBranch}`;
              const candidates = await github.paginate(github.rest.pulls.list, {
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                head: headRef,
                per_page: 100
              });
              if (candidates.length === 1) {
                return { number: candidates[0].number, source: `head=${headRef}` };
              }
              if (candidates.length > 1) {
                console.log(`Multiple PRs matched head ref ${headRef}; refusing to guess.`);
                return null;
              }
            }

            if (headSha) {
              const candidates = await github.paginate(github.rest.pulls.list, {
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                per_page: 100
              });
              const matches = candidates.filter(pr => pr.head && pr.head.sha === headSha);
              if (matches.length === 1) {
                return { number: matches[0].number, source: `head_sha=${headSha}` };
              }
              if (matches.length > 1) {
                console.log(`Multiple PRs matched head SHA ${headSha}; refusing to guess.`);
                return null;
              }
            }

            return null;
          }

          const prInfo = await resolvePrNumber();
          if (!prInfo) {
            console.log('No pull request associated with this workflow run.');
            return;
          }
          const prNumber = prInfo.number;
          console.log(`Resolved PR #${prNumber} (${prInfo.source}).`);

          const artifactsDir = path.resolve('artifacts');
          if (!fs.existsSync(artifactsDir)) {
            console.log('Artifacts directory not found.');
            return;
          }

          const MAX_BYTES = 1024 * 1024; // 1MB limit per file
          const allowedExtensions = new Set(['.txt']);

          function safeReadText(filePath) {
            const resolved = path.resolve(filePath);
            if (!resolved.startsWith(artifactsDir + path.sep)) {
              console.log(`Skipping unexpected path: ${filePath}`);
              return '';
            }
            const stat = fs.statSync(resolved);
            if (!stat.isFile()) {
              return '';
            }
            if (stat.size > MAX_BYTES) {
              console.log(`Skipping large file: ${path.basename(filePath)} (${stat.size} bytes)`);
              return '';
            }
            if (!allowedExtensions.has(path.extname(resolved))) {
              return '';
            }
            return fs.readFileSync(resolved, 'utf8');
          }

          function collectFilesByPrefix(prefix) {
            // Prefer per-version files named like `${prefix}-<version>.txt`.
            // When present, ignore the merged `${prefix}.txt` to avoid
            // duplicated contents in the PR comment. If no per-version
            // files exist, fall back to the merged file.
            const perVersionFiles = fs.readdirSync(artifactsDir)
              .filter(name => name.startsWith(prefix + '-') && name.endsWith('.txt'))
              .sort()
              .map(name => path.join(artifactsDir, name));
            if (perVersionFiles.length > 0) {
              return perVersionFiles;
            }
            const mergedFile = path.join(artifactsDir, `${prefix}.txt`);
            if (fs.existsSync(mergedFile)) {
              return [mergedFile];
            }
            return [];
          }

          function readMergedResult(baseName) {
            const mergedFile = path.join(artifactsDir, `${baseName}.txt`);
            if (fs.existsSync(mergedFile)) {
              try {
                return safeReadText(mergedFile);
              } catch (error) {
                console.log(`Error reading ${baseName}: ${error.message}`);
              }
            }
            return '';
          }

          function collectDedupedResults(prefix) {
            const files = collectFilesByPrefix(prefix);
            // Helper to normalize outputs for deduplication. For Safety we
            // strip variable header/footer lines (timestamps, ASCII art,
            // scan metadata) so runs across Python versions with identical
            // findings are grouped together.
            function canonicalize(prefix, raw) {
              if (!raw) return '';
              let s = raw.trim();
              if (prefix === 'safety-results') {
                // Reuse existing normalization to cut to the REPORT section
                s = normalizeSafetyOutput(s);
                // Remove timestamp lines, byline, scan-complete lines and
                // repeated divider blocks that differ per-run.
                s = s.split('\n').filter(l => {
                  if (!l) return false;
                  if (/^\s*Timestamp\b/i.test(l)) return false;
                  if (/by\s+pyup\.io/i.test(l)) return false;
                  if (/^Scan was completed\./i.test(l)) return false;
                  if (/^\s*\+={3,}/.test(l)) return false;
                  if (/^\s*REMEDIATIONS\b/i.test(l)) return false;
                  return true;
                }).join('\n').trim();
              }
              if (prefix === 'bandit-results') {
                // Extract the Test results block and remove run-specific lines
                const idx = s.search(/Test results:/i);
                if (idx !== -1) {
                  s = s.slice(idx);
                }
                s = s.split('\n').filter(l => {
                  if (!l) return false;
                  if (/^\s*\[main\]/.test(l)) return false;
                  if (/^\s*\[tester\]/.test(l)) return false;
                  if (/^Working\.\.\./.test(l)) return false;
                  if (/^Run started:/i.test(l)) return false;
                  if (/^Code scanned:/i.test(l)) return false;
                  if (/^Run metrics:/i.test(l)) return false;
                  if (/^Files skipped \(/i.test(l)) return false;
                  return true;
                }).join('\n').trim();
              }
              return s;
            }

            const byCanonical = new Map();
            for (const file of files) {
              try {
                const content = safeReadText(file).trim();
                if (!content) continue;
                const version = path.basename(file).replace(prefix + '-', '').replace('.txt', '');
                const canon = canonicalize(prefix, content) || content;
                if (!byCanonical.has(canon)) {
                  byCanonical.set(canon, { original: content, versions: [] });
                }
                byCanonical.get(canon).versions.push(version);
              } catch (error) {
                console.log(`Error reading ${file}: ${error.message}`);
              }
            }

            let output = '';
            // Derive a human-friendly tool label from the artifact prefix
            const toolLabelMap = {
              'bandit-results': 'Bandit',
              'safety-results': 'Safety',
              'pyright-results': 'Pyright',
              'ruff-results': 'Ruff',
              'deprecation-warnings': 'Deprecation Warnings'
            };
            const toolLabel = toolLabelMap[prefix] || prefix.replace(/-(results|warnings)$/i, '').replace(/-/g, ' ').replace(/\b\w/g, c => c.toUpperCase());

            for (const [canon, entry] of byCanonical.entries()) {
              // Sort versions using localeCompare with numeric collation so
              // versions like 3.10 sort after 3.9 correctly.
              const versions = entry.versions.sort((a, b) => a.localeCompare(b, undefined, {numeric: true, sensitivity: 'base'}));
              const display = entry.original;

              // Detect merged-only entries: when the single "version" is a
              // non-numeric marker (for example the merged file named
              // `${prefix}.txt` produces a version equal to the prefix).
              const mergedOnly = (versions.length === 1) && (!/\d/.test(versions[0]) || versions[0] === prefix);

              if (mergedOnly) {
                output += `=== Python (merged-only) ===\n${display}\n\n`;
              } else if (versions.length === 1) {
                output += `=== Python ${versions[0]} â€” ${toolLabel} ===\n${display}\n\n`;
              } else {
                output += `=== Python ${versions.join(', ')} (identical results) â€” ${toolLabel} ===\n${display}\n\n`;
              }
            }
            return output;
          }

          let banditResults = collectDedupedResults('bandit-results');
          let safetyResults = collectDedupedResults('safety-results');
          let pyrightResults = collectDedupedResults('pyright-results');
          let ruffResults = collectDedupedResults('ruff-results');
          let deprecationResults = collectDedupedResults('deprecation-warnings');

          banditResults = banditResults.trim();
          safetyResults = safetyResults.trim();
          pyrightResults = pyrightResults.trim();
          ruffResults = ruffResults.trim();
          deprecationResults = deprecationResults.trim();

          let cleanBanditResults = '';
          if (banditResults) {
            const lines = banditResults.split('\n');
            const filteredLines = lines.filter(line => !line.includes('[manager]\tWARNING\tTest in comment'));
            cleanBanditResults = filteredLines.join('\n').trim();
          }

          function normalizeSafetyOutput(raw) {
            if (!raw) {
              return '';
            }
            const reportIndex = raw.indexOf('REPORT');
            if (reportIndex !== -1) {
              return raw.slice(reportIndex).trim();
            }
            return raw.trim();
          }

          function safetyHasIssues(raw) {
            const normalized = normalizeSafetyOutput(raw);
            if (!normalized) {
              return false;
            }
            if (/No known security vulnerabilities found/i.test(normalized)) {
              return false;
            }
            const match = normalized.match(/\b(\d+)\s+vulnerab/i);
            if (match) {
              return parseInt(match[1], 10) > 0;
            }
            return true;
          }

          const hasBanditIssues = cleanBanditResults && cleanBanditResults.includes('Issue: [');
          const hasSafetyIssues = safetyHasIssues(safetyResults);
          const hasPyrightIssues = pyrightResults && !pyrightResults.includes('0 errors') && pyrightResults.trim() !== '';
          const hasRuffIssues = ruffResults && !ruffResults.includes('All checks passed!') && ruffResults.trim() !== '';
          const hasDeprecationWarnings = deprecationResults && deprecationResults.trim() !== '';

          if (!hasBanditIssues && !hasSafetyIssues && !hasPyrightIssues && !hasRuffIssues && !hasDeprecationWarnings) {
            console.log('No security, deprecation, dead code, dependency, type, or lint issues found, skipping PR comment.');
            return;
          }

          let body = '## ðŸ” Code Analysis Results\n\n';

          if (hasPyrightIssues) {
            body += '### ðŸ” Pyright Type Checking\n\n```\n' + pyrightResults + '\n```\n\n';
          }

          if (hasRuffIssues) {
            body += '### ðŸ§¹ Ruff Lint\n\n```\n' + ruffResults + '\n```\n\n';
          }

          if (hasDeprecationWarnings) {
            body += '### âš ï¸ Deprecation Warnings (Runtime)\n\n```\n' + deprecationResults + '\n```\n\n';
          }

          if (hasBanditIssues) {
            body += '### ðŸ”’ Bandit Security Analysis\n\n```\n' + cleanBanditResults + '\n```\n\n';
          }

          if (hasSafetyIssues) {
            const safetyBody = normalizeSafetyOutput(safetyResults);
            body += '### ðŸ“¦ Dependency Security Analysis (Safety)\n\n```\n' + safetyBody + '\n```\n\n';
          }

          body += '*This comment was automatically generated by the CI pipeline.*';
          // Truncate comment body to avoid exceeding API limits or causing
          // the action to fail when artifacts are extremely large.
          const MAX_COMMENT_CHARS = 60000;
          if (body.length > MAX_COMMENT_CHARS) {
            const originalLength = body.length;
            const reserveForNote = 200;
            const keep = Math.max(0, MAX_COMMENT_CHARS - reserveForNote);
            body = body.slice(0, keep);
            body += `\n\n... (truncated ${originalLength - keep} characters) ...`;
          }

          try {
            await github.rest.issues.createComment({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
            console.log('Successfully posted code analysis results to PR');
          } catch (error) {
            console.error(`Failed to post PR comment: ${error.message}`);
            throw error;
          }
